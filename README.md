üéì M‚Å∂ AI Tutor ‚Äì Socratic Learning with GPU-Powered Intelligence
‚ÄúBridging the gap between data and insight through AI-powered education‚Äù

‚∏ª

üèÅ Hackathon Context

üèÜ Organized by: Arizona State University (ASU) √ó NVIDIA

üéØ Problem Statement

Design an AI tutoring system that accelerates learning in data science. Your system should ingest machine learning course content and must incorporate GPU acceleration materials provided by NVIDIA.

‚∏ª

üí° Designed Solution ‚Äì M‚Å∂ AI Tutor

M‚Å∂ AI Tutor is an interactive, gamified tutor system designed for students and professionals exploring Data Science and GPU Acceleration. It combines:
	‚Ä¢	Retrieval-Augmented Generation (RAG)
	‚Ä¢	Large Language Models (LLMs)
	‚Ä¢	Socratic teaching methods
	‚Ä¢	Gamification elements (XP, feedback, hints)

into a dynamic and personalized learning experience.

### üîë Key Features

- **ü§ñ RAG-Enhanced Intelligence**: FAISS vector search through 40+ authoritative data science sources
- **üéÆ Gamified Learning**: Interactive flashcards, quizzes, and coding challenges
- **üöÄ GPU Acceleration Support**: Real-time detection and benchmarking of CUDA/cuDF capabilities  
- **üìö Socratic Teaching**: AI-guided questioning that promotes deep understanding
- **üí° Smart Fallbacks**: Graceful degradation from RAG ‚Üí LLM ‚Üí hardcoded responses
- **‚ö° Performance Optimization**: Intelligent device detection and model loading

## üèóÔ∏è System Architecture

```mermaid
graph TB
    A[User Query] --> B[RAG System]
    B --> C[FAISS Vector Search]
    C --> D[Context Retrieval]
    D --> E[LLM Enhancement]
    E --> F[Socratic Polishing]
    F --> G[Response Generation]
    
    B --> H[Fallback: Direct LLM]
    H --> I[Hardcoded Templates]
    
    J[Device Detection] --> K[GPU/CPU Optimization]
    K --> L[Model Loading Strategy]
```

### üß† Core Components

#### **RAG Pipeline**
- **Text Extraction**: BeautifulSoup-based web scraping from curated sources
- **Semantic Chunking**: Intelligent text segmentation for optimal retrieval
- **Vector Embeddings**: SentenceTransformers with GPU acceleration support
- **FAISS Indexing**: High-performance similarity search with caching
- **Context Ranking**: Relevance scoring and multi-source aggregation

#### **LLM Integration**
- **Primary Model**: NousResearch/Hermes-2-Pro-Mistral-7B
- **Tokenization**: Advanced tokenizer with trust_remote_code support
- **Device Optimization**: Automatic GPU/CPU detection and memory management
- **Fallback Strategy**: Graceful degradation for resource-constrained environments

#### **Game Engine**
- **Flashcard Generation**: RAG-powered content extraction for interactive cards
- **Quiz System**: Multi-choice questions with difficulty progression
- **Coding Challenges**: Pandas-to-cuDF conversion exercises with performance simulation
- **Progress Tracking**: XP system with achievement unlocks

## üìö Knowledge Base Sources

The RAG system integrates content from **40+ authoritative sources**:

### **Core Data Science Libraries**
- [pandas Documentation](https://pandas.pydata.org/docs/) - Data manipulation & analysis
- [RAPIDS cuDF](https://docs.rapids.ai/api/cudf/stable/) - GPU-accelerated DataFrames  
- [scikit-learn](https://scikit-learn.org/stable/) - Machine learning algorithms
- [PyTorch](https://pytorch.org/docs/stable/) - Deep learning framework
- [TensorFlow](https://www.tensorflow.org/) - ML platform & ecosystem
- [CuPy](https://docs.cupy.dev/en/stable/) - NumPy-compatible GPU arrays

### **GPU Computing & RAPIDS Ecosystem**
- [RAPIDS Core](https://rapids.ai/) - GPU-accelerated data science
- [RAPIDS cuML](https://docs.rapids.ai/api/cuml/stable/) - GPU machine learning
- [NVIDIA CUDA Documentation](https://developer.nvidia.com/blog/tag/cuda/)
- [cuDF-Pandas Integration](https://rapids.ai/cudf-pandas/)
- [Polars GPU Engine](https://rapids.ai/polars-gpu-engine/)
- [NetworkX-cuGraph](https://rapids.ai/nx-cugraph/)

### **Research Papers & Technical Resources**
- [GPU Acceleration Research](https://proceedings.mlr.press/v185/hagedorn22a/) - Academic insights
- [NVIDIA Tesla Architecture](https://www.nvidia.com/docs/io/116711/sc11-nv-tesla.pdf)
- [Data Science ML Textbook](https://people.smp.uq.edu.au/DirkKroese/DSML/DSML.pdf)
- [GPU-to-Web Technologies](https://www.khronos.org/assets/uploads/developers/library/2012-the-graphical-web/GPU-to-the-web_Sep2012.pdf)

### **Educational & Community Resources**
- [Awesome Data Science](https://github.com/academic/awesome-datascience) - Curated learning paths
- [GeeksforGeeks DS Guide](https://www.geeksforgeeks.org/data-science/data-science-for-beginners/)
- [LangGraph RAG Tutorials](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_agentic_rag/)
- [GPU Hardware Comparisons](https://www.nvidia.com/en-us/geforce/graphics-cards/compare/)

## üõ† Installation & Setup

### **Prerequisites**
- Python 3.8+ (recommended: 3.10+)
- CUDA 11.8+ (optional, for GPU acceleration)
- 8GB+ RAM (16GB+ recommended for large models)
- 5GB+ storage space for models and cache

### **1. Clone Repository**
```bash
git clone <repository-url>
cd AI-Tutor
```

### **2. Install Dependencies**
```bash
pip install -r requirements.txt
```

**Optional GPU Acceleration:**
```bash
# For NVIDIA GPU support
pip install faiss-gpu  # replaces faiss-cpu
pip install cudf-cu11  # RAPIDS cuDF for GPU DataFrames
```

### **3. Initialize RAG System**
The system automatically handles:
- ‚úÖ Downloads content from `src/custom_urls.txt`
- ‚úÖ Creates embeddings using SentenceTransformers  
- ‚úÖ Builds FAISS index for fast semantic search
- ‚úÖ Caches everything for instant subsequent launches

### **4. Launch via Jupyter Notebook**
jupyter notebook SemiSocratic_AI_Tutor.ipynb

The Gradio web interface will launch it with a live url.

## üéØ Usage Modes & Features

### **üéì Tutor Mode**
Interactive Q&A with intelligent responses:
- **Smart Retrieval**: RAG searches through 40+ data science sources
- **Context Grounding**: Answers backed by authoritative documentation
- **Source Attribution**: Clear indication of information sources
- **Related Suggestions**: AI-generated follow-up questions
- **Socratic Enhancement**: Responses designed to promote deeper thinking

**Example Queries:**
- *"How does cuDF compare to pandas for large datasets?"*
- *"Explain CUDA memory management best practices"*
- *"What are the key differences between supervised and unsupervised learning?"*

### **üéÆ Game Mode**

#### **üìö Flashcards**
- RAG-generated content from real documentation
- Interactive flip-card interface with dual-choice system
- Topics: CUDA, cuDF, pandas, machine learning, data visualization
- Randomized correct/incorrect feedback messages

#### **‚ùì Quiz System**
- Multi-choice questions with immediate feedback
- XP point system for gamified learning
- Progressive difficulty levels
- Topics sourced from RAG knowledge base

#### **üß© Coding Challenges**
- **CPU-to-GPU Migration**: Convert pandas code to cuDF equivalents
- **Performance Simulation**: Realistic speedup calculations
- **Benchmarking**: Compare execution times across different hardware
- **Real-world Scenarios**: Data processing, machine learning, visualization tasks

### **‚öôÔ∏è Smart Device Detection**
```python
# Automatic hardware optimization
üöÄ GPU DETECTED: NVIDIA GeForce RTX 4090
üìä GPU Memory: 24.0 GB
üî¢ GPU Count: 1
‚úÖ GPU is available and functional
‚úÖ cuDF is available and functional on GPU
```

## üîß Advanced Configuration

### **RAG System Customization**

#### **Adding Knowledge Sources**
1. Edit `src/custom_urls.txt`:
```text
https://your-data-science-resource.com
https://additional-gpu-documentation.org
```

2. Clear cache and restart:
```bash
rm src/chunks.pkl src/faiss.index
```

#### **Model Configuration**
```python
# In Final_AITutor.py
EMBED_MODEL = "sentence-transformers/all-MiniLM-L6-v2"  # Embedding model
LLM_MODEL = "NousResearch/Hermes-2-Pro-Mistral-7B"     # Language model

# Adjust RAG parameters
chunk_size = 1000        # Text chunk size for embedding
retrieval_k = 5          # Number of chunks to retrieve
similarity_threshold = 0.7  # Minimum similarity score
```

### **Performance Tuning**

#### **GPU Optimization**
```python
# Automatic device detection and optimization
device_info = {
    'main_device': 'cuda',
    'has_gpu': True,
    'device_name': 'NVIDIA GeForce RTX 4090',
    'gpu_memory': 24.0,
    'cudf_available': True
}
```

#### **Memory Management**
- **Model Loading**: Automatic FP16/FP32 selection based on GPU availability
- **Batch Processing**: Optimized chunk processing for large knowledge bases
- **Cache Strategy**: Persistent storage of embeddings and indices

## üìä Performance & Benchmarks

### **RAG System Performance**
- **Embedding Speed**: ~1000 chunks/second (GPU) | ~200 chunks/second (CPU)
- **Query Response**: <2 seconds for complex data science questions
- **Cache Hit Rate**: >95% after initial knowledge base construction
- **Memory Footprint**: ~2GB (embeddings) + ~4GB (LLM model)

### **Hardware Requirements**

| Component | Minimum | Recommended | Optimal |
|-----------|---------|-------------|---------|
| **RAM** | 8GB | 16GB | 32GB+ |
| **Storage** | 5GB | 10GB | 20GB+ |
| **GPU** | None (CPU mode) | GTX 1060 6GB | RTX 3080+ |
| **CUDA** | N/A | 11.8+ | 12.0+ |

### **Scalability Features**
- **Horizontal Scaling**: Distributed FAISS indices for large knowledge bases
- **Vertical Scaling**: Multi-GPU support for model inference
- **Edge Deployment**: CPU-only mode for resource-constrained environments


## üîÑ Customization Guide

### **Adding Custom Data Sources**
```python
# Example: Adding your own documentation
custom_sources = [
    "https://your-company-docs.com/api",
    "https://internal-wiki.org/data-science",
    "file:///path/to/local/documentation.html"
]

# Add to src/custom_urls.txt
with open('src/custom_urls.txt', 'a') as f:
    f.write('\n'.join(custom_sources))
```

### **Custom Flashcard Templates**
```python
# Modify flashcard generation in Final_AITutor.py
def custom_flashcard_template(topic, content):
    return {
        'front': f"üéØ {topic}: {content['question']}",
        'back': f"üí° {content['answer']}\n\nüìö Source: {content['source']}"
    }
```

### **Extending Quiz Categories**
```python
# Add new quiz topics
QUIZ_CATEGORIES = {
    'machine_learning': ['supervised', 'unsupervised', 'reinforcement'],
    'gpu_computing': ['cuda', 'opencl', 'rapids'],
    'data_engineering': ['etl', 'pipelines', 'streaming'],
    'your_custom_topic': ['subtopic1', 'subtopic2']
}
```

## üöÄ Future Roadmap

### **Version 2.0 Features**
- [ ] **Multi-modal RAG**: Integration of images, videos, and interactive content
- [ ] **Real-time Updates**: Live synchronization with documentation sources
- [ ] **Collaborative Learning**: Multi-user sessions and shared progress
- [ ] **Advanced Analytics**: Learning pattern analysis and personalized recommendations

### **Version 2.5 Features**
- [ ] **Voice Interface**: Speech-to-text queries and audio responses
- [ ] **AR/VR Integration**: Immersive 3D visualization of data concepts
- [ ] **Cloud Deployment**: Scalable infrastructure with API access
- [ ] **Mobile App**: iOS/Android companion applications

### **Research Integrations**
- [ ] **LangGraph Integration**: Advanced agentic RAG workflows
- [ ] **Retrieval Optimization**: Hybrid sparse/dense retrieval methods
- [ ] **Personalization Engine**: Adaptive learning path generation
- [ ] **Knowledge Graph**: Semantic relationship mapping

## ü§ù Contributing

### **Development Setup**
```bash
# Fork the repository
git clone https://github.com/your-username/AI-Tutor.git
cd AI-Tutor

# Create development environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### **Contribution Guidelines**
1. **Fork & Branch**: Create feature branches from `main`
2. **Code Quality**: Follow PEP 8, add type hints, include docstrings
3. **Testing**: Add tests for new features, ensure 80%+ coverage
4. **Documentation**: Update README.md and inline documentation
5. **Pull Request**: Submit with clear description and test results

### **Areas for Contribution**
- üåê **Knowledge Sources**: Add new authoritative data science resources
- üéÆ **Game Modes**: Design new interactive learning challenges
- üîß **Optimization**: Improve performance and memory efficiency
- üé® **UI/UX**: Enhance the Gradio interface and user experience
- üìö **Content**: Create specialized tutorials and learning paths

## üìú License & Credits

### **License**
MIT License - Feel free to use, modify, and distribute this educational tool!

### **Acknowledgments**
	‚Ä¢	üéì ASU √ó NVIDIA ‚Äî For the challenge, resources and platform to innovate.
	‚Ä¢	ü§ó Hugging Face ‚Äî For LLMs and ecosystem (transformers, model hub).
	‚Ä¢	üîç FAISS ‚Äî Vector search magic from Facebook AI Research.
	‚Ä¢	üé® Gradio ‚Äî Simplified interactive UI for learners.
	‚Ä¢	üöÄ RAPIDS (cuDF) ‚Äî GPU DataFrame computation at blazing speed.
	‚Ä¢	üìö Doc Maintainers ‚Äî The open source educators of the world.
- ** ASU Sol Supercomputer**: GPU resource to execute the RAG based LLM model.
- **ü§ó Hugging Face**: Transformers, SentenceTransformers, and model hosting
- **üîç FAISS**: High-performance similarity search by Facebook AI Research  
- **üé® Gradio**: Beautiful and intuitive web interface framework
- **üöÄ RAPIDS**: GPU-accelerated data science ecosystem by NVIDIA
- **üìö Documentation Sources**: All the amazing teams maintaining data science docs

### **Citation**
```bibtex
@software{m6_ai_tutor,
  title={M^6 AI Tutor: Intelligent Data Science \& GPU Computing Assistant},
  author={Your Name},
  year={2025},
  url={https://github.com/your-username/AI-Tutor},
  note={RAG-enhanced educational platform for data science learning}
}
```

---

<div align="center">

## üë©‚Äçüíª Team M‚Å∂ AI Tutor

| Name             | Role(s)                                                                 |
|------------------|-------------------------------------------------------------------------|
| Neha Tiwari      | Core Coder ¬∑ Prototype Ideation ¬∑ LLM Master                            |
| Darlene La Mere  | Frontfacing Detailer ¬∑ Visualization ¬∑ Task Management                  |
| Rachel Garcia    | Frontend Coder ¬∑ Debugging ¬∑ Data Sourcing                              |
| Pooja Pal        | Interface Developer ¬∑ Feature Integrator ¬∑ Detail Sweeper               |
| Sai Sudha Piratla| Creative Ideation ¬∑ Code Detailer ¬∑ Detail Specialist                   |

> *Together, we combined creativity, logic, and AI to create an immersive data science tutor experience.*
</div>
